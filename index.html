<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Lujiale Guo</title>
    <style type="text/css">
        h1{
            text-align: center;
            font-size: 50px;
        }
    </style>
    <script async defer src="https://buttons.github.io/buttons.js"></script>
</head>
<body>
<!--     <h1>Seeking for a Master Degree...</h1>   -->
    <br>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link rel="shortcut icon" type="image/x-icon" href="./favicon.ico" media="screen" />
	<style media="screen" type="text/css">
		body {
			border: 0pt none;
			font-family: inherit;
			font-size: 100%;
			font-style: inherit;
			font-weight: inherit;
			margin: 0pt;
			outline-color: invert;
			outline-style: none;
			outline-width: 0pt;
			padding: 0pt;
			vertical-align: baseline;
		}
		body {
			position: relative;
			margin: 3em auto 2em auto;
			width: 1080px;
			font-family: Times New Roman, Lato, Verdana, Helvetica, sans-serif;
			font-size: 14px;
			background: rgb(248, 246, 246);
		}
		</style>

	<script>
		var _hmt = _hmt || [];
		(function() {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?1ec4ad5c61857459aa78d5ee7ddee28d";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
		})();
	</script>
</head>

<body>
	<table align="center">
	<tr>
	<td align="center"><img border=0 style="border-radius:8px;" height="330" width="230" src="img/white profile.jpg"></td>
	<td align="center">&nbsp</td>
	<td align="center">&nbsp</td>
	<td align="center">
		<td align="center"><h2>Lucas Kwok</h2>
		     <p><font size=+1><b>Lujiale Guo</b><br><br>M.Phil in Artificial Intelligence and Bioinformatics<br><a href="https://engine.um.edu.my/" target="_blank"><b>Engineering.um</b></a></font></p>
		     <p><font size=+1>Email: <a href="mailto:mm2556910827@gmial.com"><i>mm2556910827@gmial.com</i></a></font><br></p>
		     <p align="center">
			    &nbsp;&nbsp;&nbsp;&nbsp;
			        <!-- My CV  -->
					<a href="Lucas Kwok CV.pdf" target="_blank">
				          <img src="img/logo/cv.png" alt="CV" width="40px"/>
					</a>
					&emsp;
				<!-- GitHub -->
					<a href="https://github.com/Guolujiale" target="_blank">
					  <img src="https://img.icons8.com/material-sharp/24/000000/github.png" alt="Github" width="26px"/>
					</a>
					&emsp;
				<!-- IEEE -->
					<a href="https://ieeexplore.ieee.org/author/922827195059994" target="_blank">
						<img src="img/logo/IEEE.png" alt="IEEE" width="35px"/>
					</a>
					&emsp;
				<!-- Orcid --->
					<a href= "https://orcid.org/0000-0002-5963-1478" target="_blank">
						<img src="img/logo/Orcid.png" alt="orcid" width="28px"/>
					</a>     
					&emsp;     
				<!-- LinkedIn -->
					<a href= "https://www.linkedin.com/in/lujiale-guo-1a407a281/?originalSubdomain=my" target="_blank">
						<img src="img/logo/Linkin.png" alt="Linkin" width="28px"/>
					</a>
					&emsp;
				<!-- Google Scholar -->
					<a href= "https://scholar.google.com/citations?hl=zh-CN&user=20U0RuAAAAAJ&view_op=list_works&gmla=AILGF5XrCUUol4Dgu9ab6IZncDTPPqRYDBiHumV_emqo8kvfcDaWyD1tv3z4yR2cTrwnfR2OYyd1q2vDAWfexxzbMwusnfVFY8obkASfdBg" target="_blank">
						<img src="img/logo/google-scholar.png" alt="Google Scholar" width="70px"/>
					</a>
					&emsp;
				<!-- WeChat --
					<a href= "https://github.com/Charmve/Charmve.github.io/tree/master/img/logo/My_WeChat.png" target="_blank">
						<img src="img/logo/wechat.png" alt="WeChat" width="33px"/>
					</a>
					&emsp;
				-->

            </p>
		</td>			
	</td>		
	</tr>
	</table>
	<br>
	
	<h2>Biography</h2>
	<hr/>
	<p>
	    <font size="4"> 
			I got the Master of Philosophy in Engineering science (By Research) in the <a href="https://engine.um.edu.my/" target="_blank"><b>School of Engineering</b></a>, 
		    <a href="https://um.edu.my/" target="_blank"><b>University of Malaya</b></a>. <b>(QS ranking 60)</b> <b>(July.2022 - Feb.2025)</b>
		    <br>My supervisor is <a href="https://umexpert.um.edu.my/jhchuah.html" target="_blank">Prof. 
		    CHUAH JOON HUANG</a> from the Department of Electrical Engineering, and I have studied the infrared thermal imaging detection of bearings with unbalanced data in the Image Processing (VIP) Lab.
		        <br><br>Before that, I got a bachelor's degree in Mechanical Manufacturing and Automation from <a href="https://www.stdu.edu.cn/" target="_blank"><b>Shijiazhuang 
		    Tiedao University</b></a>, and I was instructed by <a href="https://yjs.stdu.edu.cn/supervisor?code=20180730" target="_blank">Prof. 
		    Xiaohui Gu</a> in <a href="http://skltes.stdu.edu.cn/" target="_blank"><b>China National Key Laboratory of Traffic Mechanics</b></a>.<b>(Sept.2018 - June.2022)</b>
			<br><br>At present, I work as a research assistant in the reproductive department of <b>Zhongshan Hospital</b> affiliated to <b>Fudan University</b>. 
		    My current projects are as follows: 1. Using transcriptome data to analyze the mechanism of endometrial aging. 
		    2. Application of spatial single cell transcriptomics based on graph neural network in cancer.
		        
		    
			<br><br>In the application of <b>Machine Learning</b> in my previous project, I have mastered various models and skills for <b>CV</b> <b>and NLP</b> (e.g CNN, Transformer, GAN, GNN, etc.).
		    In addition, I have always been interested in <b>Bioinformatics</b>, 
		    and I have completed three project: 1. Detecting micro-bacterial types from the perspective of pictures by using the Transformer model with leap-forward connection. 2. Attribute Graph Clustering Driven Cell Map of Single Cell Spatial Transcriptome
		    3. Integrating generative adversarial networks (GAN) and attention mechanisms to predict endometrial aging and generate corresponding corrected transcriptomic data.
		    Next, I will focus on the application of <b>spatial single cell omics data in cancer and the development of spatial single cell omics data analysis methods.</b>
	    </font>
        </p>

        <!-- Education
	<p> </p>
	<p><font size="4"><span class="label">&#10148;</span> <a href="http://www.yzu.edu.cn" target="_blank"> Yangzhou University <b>(YZU)</b></a>, 
		<a href="http://wlxy.yzu.edu.cn/art/2018/12/14/art_7322_673658.html" target="_blank">School of Physical Science and Technology</a>
		</font></p>
	<table>
		
	<tr>
		<td><font size="3"><b>¬∑</b> &nbsp Bachelor of Science in Electronic Information Science & Technology, GPA: 83.2/100; Rank: 6/41 </font></td>
	</tr>
	<tr>	
		<td><font size="3"><b>¬∑</b> &nbsp <b>Dual Degree in Business English</b>, GPA: 80.76/100; Rank: 23/76, the second language: JLPT-N3:75 </font></td>
	</tr>
	<tr>	
		<td><font size="3"><b>¬∑</b> &nbsp Awards: Totally won <b>12</b> national and provincial awards, <b>28</b> municipal and school-level awards </font></td>
	</tr>
	</table>  

	<p><font size="4"><span class="label">&#10148;</span> <a href="http://jyt.jiangsu.gov.cn/art/2018/12/5/art_58320_7944692.html" target="_blank"> Winter Academic Program</a> at
		<a href="https://ese.nju.edu.cn/" target="_blank"> Nanjing University <b>(NJU)</b>, School of Electronic Science and Engineering</a>
		</font></p>
	<table>	
	<tr>
		<td><font size="3"><b>¬∑</b> &nbsp Being <b>the only student</b> who passed the selection in YZU ( Only 100 undergraduates were selected from Jiangsu Province)  </font></td>
	</tr>
	<tr>	
		<td><font size="3"><b>¬∑</b> &nbsp Took part in academic lectures and artificial intelligence (AI) development trainings, received trainings in facial recognition, target detection and image processing etc.  </font></td>
	</tr>
	<tr>	
		<td><font size="3"><b>¬∑</b> &nbsp Orally reported the study of ‚Äú<i>Identification of Agricultural Diseases and Pests Based-on Machine Vision</i>‚Äù as a <b>student representative</b> & <b>team leader</b> </font> <a href="https://www.bilibili.com/video/av91647038" target="_blank"><b>POSTER</b></a> </td>
	</tr>
	<tr>	
		<td><font size="3"><b>¬∑</b> &nbsp Completed the Arm Smarter Connected(ASC) Course on AI Development held by <i>Arm Education</i> and <i>IThing Edu</i> </font></td>
	</tr>
	</table>
 	-->
	<br>

	<h2>Research Interests</h2>
	<hr/>
	<p>
		<font size="4">
			<a href="https://arxiv.org/abs/1903.07293" target="_blank">Graph neural network</a>, 
			Computer Vision, 
			Deep Learning,
			Bioinformatics,
			Multi-Omics,
			<a href="https://arxiv.org/abs/1703.10593" target="_blank">Generative Adversarial Network</a>,
			<a href="https://www.biorxiv.org/content/10.1101/2020.09.17.301879v1" target="_blank">NLP in DNA/SCRNA-Seq</a>
		</font>
	</p>
	<br>

	<h2>Research Activity</h2>
	<hr/>
	<p>
		<font size="4">
			<a href="https://www.webofscience.com/wos/op/peer-reviews/summary" target="_blank">Reviewer of IEEE ACCESS</a>
			<br>
			<a href="https://www.webofscience.com/wos/op/peer-reviews/summary" target="_blank">Reviewer of PLOS ONE</a>
			<br>
			<a href="https://bj.huodongxing.com/event/3736471397300?qd=8828363103856" target="_blank">Yangtze River Delta Single Cell Genomics Technology Application Conference</a>
			<br>
			<a href="https://www.zs-hospital.sh.cn/fddxfszsyy/english/english.html" target="_blank">Research assistant of ZhongShan Hospital of Fudan University (2024.1.1-present)</a>
		</font>
	</p>
	<br>
    <!--
	<h2>Books</h2>
	<hr/>
	<table>
	<tr>   
		<td><font size="3"><b>1.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="180" src="img/publication/L0CV_profile-en.png" alt="Book: Computer Vision in Action" title="Book: Computer Vision in Action"></center></td>
		<td></td>
		<td></td>
		<td>
			<font size="4">
				<b>ËÆ°ÁÆóÊú∫ËßÜËßâÂÆûÊàòÊºîÁªÉÔºöÁÆóÊ≥ï‰∏éÂ∫îÁî®</b><br>
			</font>
			<font size="3">
				<b>Computer Vision in Action</b>
			</font>	    
			<font size="3">
				&nbsp;&nbsp; <br><br><b>Wei Zhang*</b>
				&nbsp;&nbsp; <br> <i><b>Computer Vision Algorithms and Applications</b>, a Chinese e-book contains source code, notebook, reader exchange community. </i> 
				&nbsp;&nbsp; <br><br>[<a href="https://charmve.github.io/L0CV-web" target="_blank">Project website</a>]
														| [<a href="https://charmve.github.io/computer-vision-in-action/" target="_blank"><b>üìò Online book</b></a>]
														| [<a href="https://github.com/Charmve/computer-vision-in-action" target="_blank"><img src="https://img.icons8.com/material-sharp/24/000000/github.png" style="vertical-align: bottom;" alt="Github" width="22px"/> GitHub</a>]
														| <a href="https://charmve.github.io/computer-vision-in-action/" target="_blank"><img src="https://img.shields.io/badge/Âú®Á∫øÈòÖËØª-ÁÆÄ‰Ωì‰∏≠Êñá-000000.svg?logo=GitBook" style="vertical-align: bottom;" alt="‰∏≠ÊñáÁîµÂ≠ê‰π¶"></a>
														<a href="https://github.com/Charmve/computer-vision-in-action/edit/master/README.md"><img src="https://img.shields.io/github/stars/Charmve/computer-vision-in-action?style=social" style="vertical-align: bottom;" alt="Stars"></a>
				<a href="https://github.com/Charmve/computer-vision-in-action/edit/master/README.md"><img src="https://img.shields.io/github/forks/Charmve/computer-vision-in-action?style=social" style="vertical-align: bottom;" alt="Forks"></a>
		</font>
		</td>
	</tr>
	</table>
	<br>
    -->
        <h2>Research Experience</h2>
	<hr/>
	<table>
	    <tr>   
		<td><font size="3"><b>1.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/STAGC.png" alt="STAGC.png"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
		<a href="https://github.com/Guolujiale/STAGC">
                <b>   Attribute Graph Clustering Driven Cell Map of Single Cell Spatial Transcriptome</b>
		</a>
		      <br> First author, under reviewing
			</font>	    
			<font size="3">
			<br>
			<br>With the development of precision and speed of spatial transcriptomics (ST) in sequencing, 
				it is becoming more and more important to use the unique characteristics of ST data for cell 
				analysis. Here, we introduce STAGC, which is a graph self-encoder method developed based on the clustering 
				of ST data. In view of the problem that traditional graph clustering algorithms are task-oriented rather than
				clustering, STAGC monitors the clustering process of self-training graphs by introducing soft labels generated
				from graph embedding itself, which can iteratively refine the clustering results. In addition, unlike the existing
				methods that directly construct graphs by calculating Euclidean distance between cell coordinates, STAGC constructs
				graphs that are more conducive to clustering task objectives by finding cells with similar gene expression patterns 
				within the threshold specified by the results of Euclidean distance.
			<br><br>
				In addition, we try to use different methods to explore the tumor microenvironment with single cell resolution. 
				This will be based on the transcriptome data of the surrounding cells of each cell (excluding this cell) for fusion and cluster analysis. 
				Comparing the results with the traditional pca method or gnn method, we find that different operation methods will bring different interesting 
				results. For example, the potential comparative experiments include: whether to carry out pca and its parameters, the way to fuse the data 
				of surrounding cells, whether to use gnn, the number of surrounding cells selected, and is it possible to define the central cell only by the surrounding cells
			<br><br> Source of dataset: Merfish.
				<br><ul class="list-inline">
					<a class="github-button"
						href="https://github.com/Guolujiale/STAGC"
						data-icon="octicon-star" data-show-count="true"
						aria-label="Star Charmve/Surface-Defect-Detection on GitHub">Star</a>
					<a class="github-button"
						href="https://github.com/Guolujiale/GAPE"
						data-icon="octicon-repo-forked" data-show-count="true"
						aria-label="Fork Charmve/Surface-Defect-Detection on GitHub">Fork</a>
			</ul>
		       <br><br>
		</td>
	    <tr>   
		<td><font size="3"><b>2.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/GAPE.png" alt="GAPE.png"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
		<a href="https://github.com/Guolujiale/GAPE">
                <b>   Generative Aging Prediction for Endometrium</b>
		</a>
		      <br> Second author, under reviewing
			</font>	    
			<font size="3">
			<br>
			<br>Aging significantly impacts the reproductive organs, particularly the endometrium, where it can lead to issues such as repeated implantation failure (RIF). 
				However, current predictive models for endometrial aging lack specificity and accuracy. In this study, we propose a novel approach GAPE, 
				that integrates generative adversarial networks (GAN) and attention mechanisms to predict endometrial aging and generate corresponding corrected 
				transcriptomic data. By using over 390 pre-processed endometrial samples from patients aged 18-43, our Age Prediction Model achieved an accuracy 
				of approximately 90%, significantly outperforming traditional models such as CNN and Lasso. We further developed an Adversarial Transcriptomic 
				Generation Model (ATGM) to expand the data set and improve model performance, with the enhanced model demonstrating improved accuracy and predictive power. 
				Integrated Gradient analysis revealed key transcriptomic features driving endometrial aging, highlighting the role of genes such as RBM39 and ZNF14. 
				These findings provide a new tool for quantifying and predicting endometrial aging, offering potential clinical applications in reproductive health, 
				particularly for aging patients facing RIF.
			<br><br> Source of dataset: Fudan University Affiliated Zhongshan Hospital Reproductive Center.
				<br><ul class="list-inline">
					<a class="github-button"
						href="https://github.com/Guolujiale/GAPE"
						data-icon="octicon-star" data-show-count="true"
						aria-label="Star Charmve/Surface-Defect-Detection on GitHub">Star</a>
					<a class="github-button"
						href="https://github.com/Guolujiale/GAPE"
						data-icon="octicon-repo-forked" data-show-count="true"
						aria-label="Fork Charmve/Surface-Defect-Detection on GitHub">Fork</a>
			</ul>
		       <br><br>
		</td>		
		    
	    <tr>   
		<td><font size="3"><b>3.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/bearing_thermal_images.png" alt="bearing_thermal_images"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
		<a href="https://ieeexplore.ieee.org/document/10433491">
                <b>   Fault Diagnosis of Rolling Bearings using Unbalanced Infrared Thermal Imaging Sample</b>
		</a>
		      <br> First author
			</font>	    
			<font size="3">
			<br>
			<br>An unsupervised learning framework named Feature-Preserving Cycle-Consistent Generative Adversarial Networks (FP-CycleGAN) is designed for defect detection in unbalanced rolling bearing infrared thermography sample. Since the classical Cycle-Consistent Generative Adversarial Networks (CycleGAN) often must balance the weights between generation, discrimination and consistency loss when doing the feature conversion from source domain to target domain, and the process often results in pattern collapse or feature loss. To avoid this problem, a new discriminator is designed to identify whether the generated image A and B belong to two different classes, and a new class loss are proposed. In order to better extract fault features and transfer features, based on the U-shaped network structure reconstruction generator, the global feature extraction ability of the network for feature maps with different sizes is improved, the number of parameters brought by the new network is reduced, and the chessboard effect of generated images is effectively avoided. Finally, the defect detection of the expanded dataset was performed using Residual Network and compared with the pre-expansion data to demonstrate the usability of the generated data and the superiority of the proposed FP-CycleGAN method for rolling bearing defect detection in small sample of infrared thermal images.
			<br><br> Source of dataset: China State Key Laboratory of Traffic Mechanics.
                        <ul class="list-inline">
                            <a class="github-button"
                                href="https://github.com/Guolujiale/FP-Cyclegan"
                                data-icon="octicon-star" data-show-count="true"
                                aria-label="Star Charmve/Surface-Defect-Detection on GitHub">Star</a>
                            <a class="github-button"
                                href="https://github.com/Guolujiale/FP-Cyclegan/fork"
                                data-icon="octicon-repo-forked" data-show-count="true"
                                aria-label="Fork Charmve/Surface-Defect-Detection on GitHub">Fork</a>
                       </ul>
		       <br><img src="https://img.icons8.com/material-sharp/24/000000/github.png" alt="Github" width="22px"/>
			    <a href="https://github.com/Guolujiale/FP-Cyclegan" target="_blank">https://github.com/Guolujiale/FP-Cyclegan</a>
		       <br><br>
		</td>
		    
	    <tr>   
		<td><font size="3"><b>4.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/beef quality classification.jpg" alt="beef quality classification.jpg"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
		<a href="https://ieeexplore.ieee.org/document/10772196">
                <b>   Autoencoder-CatBoost Model for Accurate Hyperspectral Quality Assessment of Yunling Snowflake Beef</b>
		</a>
			</font>	    
			<font size="3">
			<br>
			<br>Snowflake beef is highly valued for its nutritional benefits and exquisite taste, yet the inconsistent quality in the market poses challenges 
				for consumers in distinguishing genuine products, leading to economic losses and trust issues. This study aims to develop a rapid, accurate, 
				and non-destructive method for evaluating the quality of snowflake beef to enhance consumer satisfaction and confidence. We propose a novel
				Autoencoder-Catboost model based on an autoencoder and CatBoost classifier, utilizing hyperspectral imaging (HSI) technology to assess the quality 
				grades of Yunling Cattle snowflake beef. A total of 250 beef samples, scanned in the 900-2500 nm wavelength range, were processed using seven data 
				preprocessing techniques and two feature extraction methods. The autoencoder, comprising three layers of Transformer units, effectively extracted 
				features from the hyperspectral data, which were then classified by the CatBoost classifier. The model demonstrated superior accuracy, precision, 
				recall, and F1-score compared to traditional machine learning methods, achieving an average accuracy of 82.42%. This research introduces an innovative 
				approach by integrating Transformer-based autoencoders with CatBoost for hyperspectral data analysis, providing a new methodology for non-destructive 
				snowflake beef quality evaluation and offering valuable insights for future research in food quality assessment.
			<br><br> Source of dataset: Yunnan Engineering Technology Research Center of Agricultural Big Data, Kunming, Yunnan, China.
		       <br><br>
		</td>
		    
	    <tr>   
		<td><font size="3"><b>5.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/BTFormer_images.png" alt="BTFormer_images.png"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
				<b>   An accurate classification technique of bacteria with deep learning</b>
				<br> Second author, under reviewing
			</font>	    
			<font size="3">
			<br>
			<br>A new cross-connected neural network, BTFormer network, is proposed, which can make different feature maps interact with each other with the help of information interaction module to combine information about bacteria at macro and micro levels. We also propose a new method of self-attention mechanism, which can significantly reduce the parameters of neural network and improve the performance of neural network. We collected a data set containing five kinds of bacteria, including 3384 original images. Our network can classify bacteria within a few seconds after collecting bacterial images, with high efficiency.
			<br>
			<ul class="list-inline">
					<a class="github-button"
						href="https://github.com/Guolujiale/BTFormer"
						data-icon="octicon-star" data-show-count="true"
						aria-label="Star Charmve/Surface-Defect-Detection on GitHub">Star</a>
					<a class="github-button"
						href="https://github.com/Guolujiale/BTFormer/fork"
						data-icon="octicon-repo-forked" data-show-count="true"
						aria-label="Fork Charmve/Surface-Defect-Detection on GitHub">Fork</a>
			</ul>
			<br>
			<a href="https://github.com/Guolujiale/BTFormer" target="_blank">
				<img src="https://img.icons8.com/material-sharp/24/000000/github.png" style="vertical-align: bottom;" alt="Github" width="22px"/> GitHub
			</a>
			 | <a href="https://github.com/Guolujiale/BTFormer" target="_blank">‚úÖ demo</a>
			 | <a href="https://github.com/Guolujiale/BTFormer" target="_blank">üìÑ Homepage</a>
			<br><br>
		</td>
		    
	</tr>
	<tr>   
		<td><font size="3"><b>6.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/genept lung.jpg" alt="genept lung.jpg"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
				<b>   Using GPT-based embedding to analyze the spatial transcriptome samples of Pulmonary arterial hypertension (PAH)</b>
			</font>	    
			<font size="3">
			<br>
			    <br>   Recently, Yiqun Chen proposed a method which name is a simple and effective embedding model for single-cell biology 
				building from chatgpt (Genept, Nature biomedical engineering). This method is based on the embedding of the chatgpt 
				gene literature. By using GPT-3.5 to generate gene embedment from the text description of a single gene, and then 
				averaging the gene embedment genes weighted by each gene expression level, single-cell embedment is generated. 
				According to this single-cell embedment, cell clustering and annotation are carried out. With this method, 
				I analyzed the lung tissues of the PAH mouse model and healthy control group. Through the cell clustering and 
				annotation obtained by this method, we explored the pathological heterogeneity of lung tissues. It was found 
				that myofibroblasts and vascular fibroblasts increased in PAH, glycolysis enhanced, endothelial cells and healthy controls.
				<br><br>
             <ul class="list-inline">
                 <a class="github-button"
                     href="https://github.com/Guolujiale/Genept-for-lung"
                     data-icon="octicon-star" data-show-count="true"
                     aria-label="Star Charmve/Design-of-a-3D-Dynamic-Display-System-Based-on-Voice-Control on GitHub">Star</a>
                 <a class="github-button"
                     href="https://github.com/Guolujiale/Genept-for-lung/fork"
                     data-icon="octicon-repo-forked" data-show-count="true"
                     aria-label="Fork Charmve/Design-of-a-3D-Dynamic-Display-System-Based-on-Voice-Control on GitHub">Fork</a>
             </ul>
			    <br>
				<a href="https://github.com/Guolujiale/Genept-for-lung" target="_blank">
					<img src="https://img.icons8.com/material-sharp/24/000000/github.png" style="vertical-align: bottom;" alt="Github" width="22px"/> GitHub
				</a>
				   | <a href="https://github.com/Guolujiale/Genept-for-lung" target="_blank">üìÑ Paper (Chinese)</a> 
				   | <a href="https://github.com/Guolujiale/Genept-for-lung" target="_blank">üî≥ Slides</a> 
				   | <a href="https://github.com/Guolujiale/Genept-for-lung" target="_blank">üìÑ Patents</a> 
				   | <a href="https://github.com/Guolujiale/Genept-for-lung" target="_blank">üé• Video</a>
				   | <a href="https://github.com/Guolujiale/Genept-for-lung" target="_blank">üöÄ EmotionCube</a>
		    	<br><br>
			</font>
		</td>
	</table>
	<br> 

	
	<!--
	<h2>‚ú® News! ‚ú®</h2>
	<hr/>
	<ul>
		<li><font size="4"><b>2020.03.06:</b> 1 paper was accepted by <a href="https://www.2020.ieeeicme.org/" target="_blank">ICME 2020</a> !</font></li>
		<li><font size="4"><b>2020.02.24:</b> 1 paper was accepted by <a href="http://cvpr2020.thecvf.com/" target="_blank">CVPR 2020</a> !</font></li>
	</ul>
	<br>
	-->
	
	<h2>Publications &nbsp;<a href="https://scholar.google.com/citations?hl=zh-CN&user=20U0RuAAAAAJ&view_op=list_works&gmla=AILGF5XrCUUol4Dgu9ab6IZncDTPPqRYDBiHumV_emqo8kvfcDaWyD1tv3z4yR2cTrwnfR2OYyd1q2vDAWfexxzbMwusnfVFY8obkASfdBg" target="_blank"><img src="img/logo/google-scholar.png" alt="Google Scholar" width="64px"/></a></h2>
	<hr/>
	<table>
		<tr>
			<td><br><font size="4"><b>2023</b></font></td>
		</tr>
		<tr>
			<td><font size="4">1.&nbsp</font></td>
			<td><center><img width="240" height="135" src="img/publication/FP-cyclegan Paper.jpg"></center></td>
			<td>
				<font size="4">
					<b>Unsupervised Feature-Preserving CycleGAN for Fault Diagnosis of Rolling Bearings using Unbalanced Infrared Thermal Imaging Sample</b><span style="color: red;">--IEEE Access
					<br>[doi: 10.1109/ACCESS.2024.3365551](https://ieeexplore.ieee.org/document/10433491)</span>
				</font>
				<font size="3">
					&nbsp;&nbsp; <br><br><b>Lujiale Guo*, Joon Huang Chuaha*, W. J. K. Raymonda*, Xiaohui Gub, Jie Yaob , Xiangqian Chang</b>
					&nbsp;&nbsp; <br> <i><b>Department of Electrical Engineering, Faculty of Engineering, Universiti Malaya, 50603 Kuala Lumpur, Malaysia</b>.
					&nbsp;&nbsp; <br><br>[<a href="https://github.com/Guolujiale/FP-Cyclegan" target="_blank"><b>PDF</b></a>]
																| [<a href="https://github.com/Guolujiale/FP-Cyclegan" target="_blank">BibTeX</a>]
																| [<a href="https://github.com/Guolujiale/FP-Cyclegan" target="_blank">EndNote</a>]
				</font>
			</td>
		</tr>
		
		<tr>
			<td><font size="4">1.&nbsp</font></td>
			<td><center><img width="240" height="300" src="img/publication/beef auto encoder.png"></center></td>
			<td>
				<font size="4">
					<b>Autoencoder-CatBoost Model for Accurate Hyperspectral Quality Assessment of Yunling Snowflake Beef</b><span style="color: red;">--IEEE Access
					<br>[doi: 10.1109/ACCESS.2024.3510035](https://ieeexplore.ieee.org/document/10772196)</span>
				</font>
				<font size="3">
					&nbsp;&nbsp; <br><br><b>Lutao Gao; Lilian Zhang; Jian Chen; Lin Peng; Lujiale Guo; Linnan Yang</b>
					&nbsp;&nbsp; <br> <i><b>Zhongshan Hospital, Fudan University, Shanghai, China</b>.
					&nbsp;&nbsp; <br><br>[<a href="https://ieeexplore.ieee.org/document/10772196" target="_blank"><b>PDF</b></a>]
																| [<a href="https://ieeexplore.ieee.org/document/10772196" target="_blank">BibTeX</a>]
																| [<a href="https://ieeexplore.ieee.org/document/10772196" target="_blank">EndNote</a>]
				<br><br>
				</font>
			</td>
		</tr>
		<tr>
			<td><font size="4">2.&nbsp</font></td>
			<td><center><img width="271" height="258" src="img/publication/BTFormer.png"></center></td>
			<td>
				<font size="4">
					&nbsp;&nbsp;<b>BTFormer: An accurate classification technique of bacteria with deep learning</b><span style="color: red;">--Under review...</span>
				</font>
				<font size="3">
					<br><br>&nbsp;&nbsp;Xiangqian Chang, <b>Lujiale Guo</b>, Yuequn Ma, Geok Yuan Annie Tan, Xuechen Tian, Fatimah Ibrahima, Bingrui Huang, Joon Huang Chuah
					<br><br>&nbsp;&nbsp;[<b><a href="https://github.com/Guolujiale/BTFormer" target="_blank">PDF</a></b>] 
					| [<a href="https://github.com/Guolujiale/BTFormer" target="_blank">Supplemental Material</a>]
					<br><br><details><summary>BibTeX</summary>https://github.com/Guolujiale/BTFormer</details>
				</font>
			</td>
		</tr>
	</table>

		
	<h2>Skills</h2>
	<hr/>
	<table>
	<tr>	
		<td><font size="4"><b> ‚Ä¢ Programming: Rapid Ai, cudf, R, Matlab, Python {Pytorch, Tensorflow, Pyg, Scanpy, Pandas, Numpy, sklearn}.</b></font></td>
	</tr>
	<tr>	
		<td><font size="4"><b> ‚Ä¢ Tools LATEX, Linux, Anaconda, Git, Docker, Abode Illustrator, HTML.</b></font></td>
	</tr>
	</table>
	<br>
	
	<h2>Academic awards & Scholarships</h2>
	<hr/>
	<table>
	<tr>	
		<td><br><b>1.</b>&nbsp; <font size="4">The third prize of "Chinese college students' engineering training ability competition--UAV" (2021-2022)</font></td>
	</tr>
	<tr>	
		<td><b>2.</b> &nbsp; <font size="4">The second prize of "Chinese college students' engineering training ability competition--Automatic Tracking Vehicle" (CETC) (2021-2022)</font> </td>
	</tr>
	<tr>	
		<td><b>3.</b> &nbsp; <font size="4">The first prize of ‚ÄúChinese University Student Innovation Capacity Competition" (2020-2021)</font> </td>
	</tr>
	<tr>	
		<td><b>4.</b> &nbsp; <font size="4">Shijiazhuang Tiedao University "Most Beautiful College Students"Scholarship (2020-2021)</font> </td>
	</tr>
	</table>
	<br>

	<br>
	<!-- <h2>Website visit statistics</h2>-->
	<hr/>

	<div style="text-align: center; display: none;"><script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=fY8GIOs749Z2RzLFv5s_cU8HOl5WzjGIQIsI1TwGxlU&cl=ffffff&w=a"></script>
	</div>

    <div id="copyright" align="right">
        <p>Copyright&copy; 2020~2025 Lujiae Guo.</p>
</body>
</html>
